import torchvision.transforms as transformsfrom torchvision.datasets import CIFAR10from torch.utils.data import DataLoader import timm import torchimport torch.nn as nnimport torch.optim as optimdevice = torch.device("cuda" if torch.cuda.is_available() else "cpu")#Resize the CIFAR-10 images such that they can be processed by our pretrained ViTtransform = transforms.Compose([    transforms.Resize((224, 224)),    transforms.ToTensor(),    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])#Download and store the CIFAR-10 dataset inside colab and split it in train and test datasetstrain_dataset = CIFAR10(root='data', train=True, download=True, transform=transform)test_dataset = CIFAR10(root='data', train=False, download=True, transform=transform)train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2) # ViT Image Classification Modelmodel = timm.create_model("vit_base_patch16_224", pretrained=True)# Modify the classification head for CIFAR-10num_classes = 10model.head = nn.Linear(model.head.in_features, num_classes) # Move model to GPUmodel = model.to(device)#Optimizerlearning_rate = 0.001betas = (0.9, 0.999)epsilon = 1e-08criterion = nn.CrossEntropyLoss()optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, eps=epsilon)#optimizer = optim.Adam(model.parameters(), lr=2e-4) num_epochs = 5for epoch in range(num_epochs):    model.train()    total_loss = 0.0    total_correct = 0    for batch_idx, (inputs, labels) in enumerate(train_dataloader):        # Move inputs and labels to GPU        inputs, labels = inputs.to(device), labels.to(device)                optimizer.zero_grad()        outputs = model(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        # Calculate training accuracy        _, predicted = torch.max(outputs, 1)        total_correct += (predicted == labels).sum().item()        total_loss += loss.item()        # Print loss for every N batches (adjust N as needed)        print_interval = 10        if batch_idx % print_interval == 0:            avg_loss = total_loss / (batch_idx + 1)            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, '                  f'Loss: {avg_loss:.4f}')    # Calculate average training loss and accuracy    avg_train_loss = total_loss / len(train_dataloader)    train_accuracy = total_correct / len(train_dataloader.dataset)    # Validate the model    model.eval()    total_val_loss = 0.0    total_val_correct = 0    with torch.no_grad():        for inputs, labels in test_dataloader:                        # Move inputs and labels to GPU            inputs, labels = inputs.to(device), labels.to(device)                        outputs = model(inputs)            val_loss = criterion(outputs, labels)            # Calculate validation accuracy            _, predicted = torch.max(outputs, 1)            total_val_correct += (predicted == labels).sum().item()            total_val_loss += val_loss.item()    # Calculate average validation loss and accuracy    avg_val_loss = total_val_loss / len(test_dataloader)    val_accuracy = total_val_correct / len(test_dataloader.dataset)    # Print epoch statistics    print(f'Epoch {epoch + 1}/{num_epochs}, '          f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '          f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')